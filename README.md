# BERT + UMAP + HDBSCAN Text Clustering Application

Advanced text clustering application using BERT embeddings, UMAP dimensionality reduction, and HDBSCAN clustering. This Streamlit-based web application provides an intuitive interface for analyzing and visualizing text clusters.

## üöÄ „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊ¶ÇË¶Å

„Åì„ÅÆ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅØ„ÄÅËá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜÔºàNLPÔºâ„ÅÆÊúÄÊñ∞ÊäÄË°ì„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„ÅüÈ´òÂ∫¶„Å™„ÉÜ„Ç≠„Çπ„Éà„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞„Ç∑„Çπ„ÉÜ„É†„Åß„Åô„ÄÇBERT„Å´„Çà„ÇãÊÑèÂë≥ÁöÑÂüã„ÇÅËæº„Åø„ÄÅUMAP„Å´„Çà„ÇãÊ¨°ÂÖÉÂâäÊ∏õ„ÄÅHDBSCAN„Å´„Çà„ÇãÂØÜÂ∫¶„Éô„Éº„Çπ„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞„ÇíÁµ±Âêà„Åó„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„Éá„Éº„Çø„ÅÆËá™ÂãïÁöÑ„Å™ÂàÜÈ°û„Å®ÂèØË¶ñÂåñ„ÇíÂÆüÁèæ„Åó„Åæ„Åô„ÄÇ

## üìã ÁõÆÊ¨°

- [Ê©üËÉΩ](#Ê©üËÉΩ)
- [„Ç¢„É´„Ç¥„É™„Ç∫„É†Ë©≥Á¥∞](#„Ç¢„É´„Ç¥„É™„Ç∫„É†Ë©≥Á¥∞)
- [„Éï„Ç°„Ç§„É´ÊßãÊàê](#„Éï„Ç°„Ç§„É´ÊßãÊàê)
- [„Éó„É≠„Ç∞„É©„É†„Éï„É≠„Éº](#„Éó„É≠„Ç∞„É©„É†„Éï„É≠„Éº)
- [„Ç§„É≥„Çπ„Éà„Éº„É´](#„Ç§„É≥„Çπ„Éà„Éº„É´)
- [‰ΩøÁî®ÊñπÊ≥ï](#‰ΩøÁî®ÊñπÊ≥ï)
- [„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£](#„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£)
- [Ë®≠ÂÆö](#Ë®≠ÂÆö)
- [„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ](#„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ)
- [‰æã](#‰æã)
- [API „É™„Éï„Ç°„É¨„É≥„Çπ](#api-„É™„Éï„Ç°„É¨„É≥„Çπ)
- [„Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞](#„Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞)
- [Ë≤¢ÁåÆ](#Ë≤¢ÁåÆ)
- [„É©„Ç§„Çª„É≥„Çπ](#„É©„Ç§„Çª„É≥„Çπ)

## Ê©üËÉΩ

### üß† **BERT Embeddings**
- Multiple BERT model support (Sentence Transformers and raw BERT)
- High-quality text embeddings for semantic understanding
- Configurable model selection

### üó∫Ô∏è **UMAP Dimensionality Reduction**
- Efficient dimensionality reduction preserving local and global structure
- Configurable parameters (neighbors, minimum distance, components)
- Support for 2D and 3D visualizations

### üîç **HDBSCAN Clustering**
- Density-based clustering with noise detection
- Automatic cluster number determination
- Robust to outliers and varying cluster densities

### üìä **Interactive Visualizations**
- 2D and 3D UMAP scatter plots
- Cluster distribution charts
- Word clouds for each cluster
- Interactive hover information

### üìà **Advanced Analysis**
- Clustering quality metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin)
- Text similarity analysis
- Topic modeling with LDA
- Export functionality

## „Ç¢„É´„Ç¥„É™„Ç∫„É†Ë©≥Á¥∞

### ü§ñ BERT (Bidirectional Encoder Representations from Transformers)

BERT„ÅØ„ÄÅTransformer„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Å´Âü∫„Å•„ÅèÂèåÊñπÂêë„ÅÆË®ÄË™û„É¢„Éá„É´„Åß„Åô„ÄÇ„Åì„ÅÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Åß„ÅØ„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„ÅÆÊÑèÂë≥ÁöÑË°®Áèæ„ÇíÁîüÊàê„Åô„Çã„Åü„ÇÅ„Å´‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

#### **BERT„ÅÆ‰ªïÁµÑ„Åø**

1. **„Éà„Éº„ÇØ„É≥Âåñ (Tokenization)**
   - „ÉÜ„Ç≠„Çπ„Éà„ÇíWordPiece„Éà„Éº„ÇØ„É≥„Å´ÂàÜÂâ≤
   - ÁâπÊÆä„Éà„Éº„ÇØ„É≥Ôºà[CLS], [SEP]Ôºâ„ÇíËøΩÂä†
   - ‰ΩçÁΩÆ„Ç®„É≥„Ç≥„Éº„Éá„Ç£„É≥„Ç∞„ÇíÈÅ©Áî®

2. **Transformer„Ç®„É≥„Ç≥„Éº„ÉÄ„Éº**
   - 12Â±§„Åæ„Åü„ÅØ24Â±§„ÅÆTransformer„Éñ„É≠„ÉÉ„ÇØ
   - ÂêÑÂ±§„ÅßËá™Â∑±Ê≥®ÊÑèÊ©üÊßãÔºàSelf-AttentionÔºâ„ÇíÈÅ©Áî®
   - ÂèåÊñπÂêë„ÅÆÊñáËÑàÁêÜËß£„ÇíÂÆüÁèæ

3. **Âüã„ÇÅËæº„ÅøÁîüÊàê**
   - [CLS]„Éà„Éº„ÇØ„É≥„ÅÆÊúÄÁµÇÂ±§Âá∫Âäõ„ÇíÊñáÂÖ®‰Ωì„ÅÆË°®Áèæ„Å®„Åó„Å¶‰ΩøÁî®
   - Âπ≥Âùá„Éó„Éº„É™„É≥„Ç∞„Åæ„Åü„ÅØÊúÄÂ§ß„Éó„Éº„É™„É≥„Ç∞„ÅßÊñáÂüã„ÇÅËæº„Åø„ÇíÁîüÊàê

#### **‰ΩøÁî®„É¢„Éá„É´**

```python
# „Éá„Éï„Ç©„É´„Éà„É¢„Éá„É´
"sentence-transformers/all-MiniLM-L6-v2"  # 384Ê¨°ÂÖÉ„ÄÅÈ´òÈÄü
"sentence-transformers/all-mpnet-base-v2"  # 768Ê¨°ÂÖÉ„ÄÅÈ´òÁ≤æÂ∫¶
"bert-base-uncased"  # 768Ê¨°ÂÖÉ„ÄÅÊ®ôÊ∫ñBERT
```

#### **Âüã„ÇÅËæº„ÅøÁîüÊàê„Éó„É≠„Çª„Çπ**

```python
def generate_embeddings(self, texts: List[str]) -> np.ndarray:
    # 1. „ÉÜ„Ç≠„Çπ„Éà„ÅÆÂâçÂá¶ÁêÜ
    processed_texts = self.preprocess_texts(texts)
    
    # 2. BERT„É¢„Éá„É´„Å´„Çà„ÇãÂüã„ÇÅËæº„ÅøÁîüÊàê
    embeddings = self.model.encode(processed_texts)
    
    # 3. Ê≠£Ë¶èÂåñÔºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ
    embeddings = self.normalize_embeddings(embeddings)
    
    return embeddings
```

### üó∫Ô∏è UMAP (Uniform Manifold Approximation and Projection)

UMAP„ÅØ„ÄÅÈ´òÊ¨°ÂÖÉ„Éá„Éº„Çø„Çí‰ΩéÊ¨°ÂÖÉÁ©∫Èñì„Å´Âüã„ÇÅËæº„ÇÄ„Åü„ÇÅ„ÅÆÊ¨°ÂÖÉÂâäÊ∏õ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Åß„Åô„ÄÇt-SNE„Å®ÊØîËºÉ„Åó„Å¶È´òÈÄü„Åß„ÄÅ„Çà„ÇäËâØ„ÅÑÂ§ßÂüüÊßãÈÄ†„ÅÆ‰øùÊåÅ„ÅåÁâπÂæ¥„Åß„Åô„ÄÇ

#### **UMAP„ÅÆ„Ç¢„É´„Ç¥„É™„Ç∫„É†**

1. **„Ç∞„É©„ÉïÊßãÁØâ**
   ```python
   # kËøëÂÇç„Ç∞„É©„Éï„ÅÆÊßãÁØâ
   def build_graph(embeddings, n_neighbors=15):
       # ÂêÑÁÇπ„Å´„Å§„ÅÑ„Å¶kÂÄã„ÅÆÊúÄËøëÂÇç„ÇíË¶ã„Å§„Åë„Çã
       # Èáç„Åø‰ªò„Åç„Ç∞„É©„Éï„ÇíÊßãÁØâ
       return graph
   ```

2. **Á¢∫ÁéáÁöÑÂüã„ÇÅËæº„Åø**
   ```python
   # ‰ΩéÊ¨°ÂÖÉÁ©∫Èñì„Åß„ÅÆÊúÄÈÅ©Âåñ
   def optimize_embedding(graph, n_components=2):
       # Á¢∫ÁéáÁöÑÂãæÈÖçÈôç‰∏ãÊ≥ï„ÅßÂüã„ÇÅËæº„Åø„ÇíÊúÄÈÅ©Âåñ
       # Â±ÄÊâÄÊßãÈÄ†„Å®Â§ßÂüüÊßãÈÄ†„ÅÆ„Éê„É©„É≥„Çπ„ÇíÂèñ„Çã
       return low_dim_embedding
   ```

#### **‰∏ªË¶Å„Éë„É©„É°„Éº„Çø**

- **n_neighbors**: ËøëÂÇçÁÇπ„ÅÆÊï∞Ôºà„Éá„Éï„Ç©„É´„Éà: 15Ôºâ
  - Â∞è„Åï„ÅÑÂÄ§: Â±ÄÊâÄÊßãÈÄ†„ÇíÈáçË¶ñ
  - Â§ß„Åç„ÅÑÂÄ§: Â§ßÂüüÊßãÈÄ†„ÇíÈáçË¶ñ

- **min_dist**: ÁÇπÈñì„ÅÆÊúÄÂ∞èË∑ùÈõ¢Ôºà„Éá„Éï„Ç©„É´„Éà: 0.1Ôºâ
  - „ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞„ÅÆÂØÜÂ∫¶„ÇíÂà∂Âæ°

- **n_components**: Âá∫ÂäõÊ¨°ÂÖÉÊï∞Ôºà„Éá„Éï„Ç©„É´„Éà: 2Ôºâ
  - 2DÂèØË¶ñÂåñ„Åæ„Åü„ÅØ3DÂèØË¶ñÂåñ

#### **ÂÆüË£Ö‰æã**

```python
def apply_umap(self, embeddings: np.ndarray) -> np.ndarray:
    # „Éá„Éº„Çø„ÅÆÊ®ôÊ∫ñÂåñ
    embeddings_scaled = self.scaler.fit_transform(embeddings)
    
    # UMAPÈÅ©Áî®
    self.umap_reducer = umap.UMAP(
        n_neighbors=15,
        min_dist=0.1,
        n_components=2,
        metric='cosine',
        random_state=42
    )
    
    umap_embeddings = self.umap_reducer.fit_transform(embeddings_scaled)
    return umap_embeddings
```

### üîç HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise)

HDBSCAN„ÅØ„ÄÅÂØÜÂ∫¶„Éô„Éº„Çπ„ÅÆÈöéÂ±§ÁöÑ„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞„Ç¢„É´„Ç¥„É™„Ç∫„É†„Åß„Åô„ÄÇDBSCAN„ÅÆÊã°ÂºµÁâà„Åß„ÄÅÁï∞„Å™„ÇãÂØÜÂ∫¶„ÅÆ„ÇØ„É©„Çπ„Çø„ÇíËá™ÂãïÁöÑ„Å´Ê§úÂá∫„Åß„Åç„Åæ„Åô„ÄÇ

#### **HDBSCAN„ÅÆ„Ç¢„É´„Ç¥„É™„Ç∫„É†**

1. **Áõ∏‰∫íÂà∞ÈÅîË∑ùÈõ¢„Ç∞„É©„ÉïÊßãÁØâ**
   ```python
   def build_mutual_reachability_graph(data, min_samples=5):
       # ÂêÑÁÇπ„ÅÆcore distance„ÇíË®àÁÆó
       # Áõ∏‰∫íÂà∞ÈÅîË∑ùÈõ¢„ÇíË®àÁÆó
       # ÊúÄÂ∞èÂÖ®ÂüüÊú®„ÇíÊßãÁØâ
       return mst
   ```

2. **ÈöéÂ±§ÁöÑ„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞**
   ```python
   def hierarchical_clustering(mst):
       # ÊúÄÂ∞èÂÖ®ÂüüÊú®„Åã„ÇâÈöéÂ±§ÊßãÈÄ†„ÇíÊßãÁØâ
       # „ÇØ„É©„Çπ„Çø„ÅÆÈöéÂ±§„ÇíÊ±∫ÂÆö
       return hierarchy
   ```

3. **„ÇØ„É©„Çπ„ÇøÈÅ∏Êäû**
   ```python
   def select_clusters(hierarchy, min_cluster_size=5):
       # ÂÆâÂÆöÊÄß„Å´Âü∫„Å•„ÅÑ„Å¶„ÇØ„É©„Çπ„Çø„ÇíÈÅ∏Êäû
       # „Éé„Ç§„Ç∫ÁÇπ„ÇíË≠òÂà•
       return cluster_labels
   ```

#### **‰∏ªË¶Å„Éë„É©„É°„Éº„Çø**

- **min_cluster_size**: ÊúÄÂ∞è„ÇØ„É©„Çπ„Çø„Çµ„Ç§„Ç∫Ôºà„Éá„Éï„Ç©„É´„Éà: 5Ôºâ
  - Â∞è„Åï„Åô„Åé„Çã„ÇØ„É©„Çπ„Çø„ÇíÈô§Â§ñ

- **min_samples**: ËøëÂÇç„ÅÆÊúÄÂ∞è„Çµ„É≥„Éó„É´Êï∞Ôºà„Éá„Éï„Ç©„É´„Éà: 3Ôºâ
  - ÂØÜÂ∫¶„ÅÆÈñæÂÄ§„ÇíÂà∂Âæ°

- **cluster_selection_epsilon**: „ÇØ„É©„Çπ„ÇøÈÅ∏Êäû„ÅÆÈñæÂÄ§Ôºà„Éá„Éï„Ç©„É´„Éà: 0.0Ôºâ
  - „ÇØ„É©„Çπ„Çø„ÅÆÂÆâÂÆöÊÄß„ÇíÂà∂Âæ°

#### **ÂÆüË£Ö‰æã**

```python
def apply_hdbscan(self, embeddings: np.ndarray) -> np.ndarray:
    # HDBSCAN„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞
    self.hdbscan_clusterer = hdbscan.HDBSCAN(
        min_cluster_size=5,
        min_samples=3,
        cluster_selection_epsilon=0.0,
        alpha=1.0,
        prediction_data=True
    )
    
    cluster_labels = self.hdbscan_clusterer.fit_predict(embeddings)
    return cluster_labels
```

#### **„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞ÂìÅË≥™Ë©ï‰æ°**

```python
def evaluate_clustering(embeddings, labels):
    # „Ç∑„É´„Ç®„ÉÉ„Éà„Çπ„Ç≥„Ç¢
    silhouette = silhouette_score(embeddings, labels)
    
    # Calinski-Harabasz„Çπ„Ç≥„Ç¢
    calinski = calinski_harabasz_score(embeddings, labels)
    
    # Davies-Bouldin„Çπ„Ç≥„Ç¢
    davies = davies_bouldin_score(embeddings, labels)
    
    return {
        'silhouette': silhouette,
        'calinski_harabasz': calinski,
        'davies_bouldin': davies
    }
```

## „Éï„Ç°„Ç§„É´ÊßãÊàê

### üìÅ „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊßãÈÄ†

```
bert_umap_hdbscan/
‚îú‚îÄ‚îÄ app.py                    # „É°„Ç§„É≥Streamlit„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥
‚îú‚îÄ‚îÄ bert_embedder.py          # BERTÂüã„ÇÅËæº„ÅøÁîüÊàê„É¢„Ç∏„É•„Éº„É´
‚îú‚îÄ‚îÄ clustering_manager.py     # UMAP/HDBSCAN„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞ÁÆ°ÁêÜ
‚îú‚îÄ‚îÄ visualization_manager.py  # ÂèØË¶ñÂåñÁÆ°ÁêÜ„É¢„Ç∏„É•„Éº„É´
‚îú‚îÄ‚îÄ text_processor.py         # „ÉÜ„Ç≠„Çπ„ÉàÂâçÂá¶ÁêÜ„É¢„Ç∏„É•„Éº„É´
‚îú‚îÄ‚îÄ pyproject.toml           # „Éó„É≠„Ç∏„Çß„ÇØ„ÉàË®≠ÂÆö„Å®‰æùÂ≠òÈñ¢‰øÇ
‚îú‚îÄ‚îÄ README.md                # „Éó„É≠„Ç∏„Çß„ÇØ„Éà„Éâ„Ç≠„É•„É°„É≥„Éà
‚îî‚îÄ‚îÄ .venv/                   # ‰ªÆÊÉ≥Áí∞Â¢É
```

### üìÑ „Éï„Ç°„Ç§„É´Ë©≥Á¥∞Ë™¨Êòé

#### `app.py` - „É°„Ç§„É≥„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥
- **ÂΩπÂâ≤**: Streamlit Web„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„É°„Ç§„É≥„Ç®„É≥„Éà„É™„Éº„Éù„Ç§„É≥„Éà
- **Ê©üËÉΩ**:
  - „É¶„Éº„Ç∂„Éº„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ„ÅÆÊßãÁØâ
  - „ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÅÆÁÆ°ÁêÜ
  - „Çª„ÉÉ„Ç∑„Éß„É≥Áä∂ÊÖã„ÅÆÁÆ°ÁêÜ
  - „Çø„Éñ„Éô„Éº„Çπ„ÅÆ„Éä„Éì„Ç≤„Éº„Ç∑„Éß„É≥

#### `bert_embedder.py` - BERTÂüã„ÇÅËæº„ÅøÁîüÊàê
- **ÂΩπÂâ≤**: BERT„É¢„Éá„É´„ÅÆÁÆ°ÁêÜ„Å®„ÉÜ„Ç≠„Çπ„ÉàÂüã„ÇÅËæº„Åø„ÅÆÁîüÊàê
- **‰∏ªË¶Å„ÇØ„É©„Çπ**: `BERTEmbedder`
- **Ê©üËÉΩ**:
  - Ë§áÊï∞„ÅÆBERT„É¢„Éá„É´„ÅÆ„Çµ„Éù„Éº„Éà
  - Âüã„ÇÅËæº„ÅøÁîüÊàê„Å®Ê≠£Ë¶èÂåñ
  - È°û‰ººÂ∫¶Ë®àÁÆó
  - „É¢„Éá„É´ÊÉÖÂ†±„ÅÆÂèñÂæó

#### `clustering_manager.py` - „ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞ÁÆ°ÁêÜ
- **ÂΩπÂâ≤**: UMAPÊ¨°ÂÖÉÂâäÊ∏õ„Å®HDBSCAN„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞„ÅÆÂÆüË°å
- **‰∏ªË¶Å„ÇØ„É©„Çπ**: `ClusteringManager`
- **Ê©üËÉΩ**:
  - UMAPÊ¨°ÂÖÉÂâäÊ∏õ„ÅÆÈÅ©Áî®
  - HDBSCAN„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞„ÅÆÂÆüË°å
  - „ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞Áµ±Ë®à„ÅÆË®àÁÆó
  - „Éë„É©„É°„Éº„ÇøÊúÄÈÅ©Âåñ

#### `visualization_manager.py` - ÂèØË¶ñÂåñÁÆ°ÁêÜ
- **ÂΩπÂâ≤**: „ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞ÁµêÊûú„ÅÆÂèØË¶ñÂåñ
- **‰∏ªË¶Å„ÇØ„É©„Çπ**: `VisualizationManager`
- **Ê©üËÉΩ**:
  - 2D/3D UMAPÊï£Â∏ÉÂõ≥„ÅÆ‰ΩúÊàê
  - „ÇØ„É©„Çπ„ÇøÂàÜÂ∏É„ÉÅ„É£„Éº„Éà
  - „ÉØ„Éº„Éâ„ÇØ„É©„Ç¶„ÉâÁîüÊàê
  - „Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ„Éó„É≠„ÉÉ„Éà

#### `text_processor.py` - „ÉÜ„Ç≠„Çπ„ÉàÂâçÂá¶ÁêÜ
- **ÂΩπÂâ≤**: „ÉÜ„Ç≠„Çπ„Éà„ÅÆÂâçÂá¶ÁêÜ„Å®„ÇØ„É™„Éº„Éã„É≥„Ç∞
- **‰∏ªË¶Å„ÇØ„É©„Çπ**: `TextProcessor`
- **Ê©üËÉΩ**:
  - „ÉÜ„Ç≠„Çπ„Éà„ÇØ„É™„Éº„Éã„É≥„Ç∞„Å®Ê≠£Ë¶èÂåñ
  - „Çπ„Éà„ÉÉ„Éó„ÉØ„Éº„ÉâÈô§Âéª
  - „É¨„É≥„ÉûÂåñ
  - „ÉÜ„Ç≠„Çπ„ÉàÁµ±Ë®à„ÅÆË®àÁÆó

## „Éó„É≠„Ç∞„É©„É†„Éï„É≠„Éº

### üîÑ „É°„Ç§„É≥„Éó„É≠„Çª„Çπ„Éï„É≠„Éº

```mermaid
graph TD
    A[„ÉÜ„Ç≠„Çπ„ÉàÂÖ•Âäõ] --> B[„ÉÜ„Ç≠„Çπ„ÉàÂâçÂá¶ÁêÜ]
    B --> C[BERTÂüã„ÇÅËæº„ÅøÁîüÊàê]
    C --> D[UMAPÊ¨°ÂÖÉÂâäÊ∏õ]
    D --> E[HDBSCAN„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞]
    E --> F[ÁµêÊûúÂèØË¶ñÂåñ]
    F --> G[ÂàÜÊûê„ÉªË©ï‰æ°]
    G --> H[ÁµêÊûú„Ç®„ÇØ„Çπ„Éù„Éº„Éà]
    
    B --> B1[„ÉÜ„Ç≠„Çπ„Éà„ÇØ„É™„Éº„Éã„É≥„Ç∞]
    B --> B2[Ê≠£Ë¶èÂåñ]
    B --> B3[„Éà„Éº„ÇØ„É≥Âåñ]
    
    C --> C1[„É¢„Éá„É´Ë™≠„ÅøËæº„Åø]
    C --> C2[Âüã„ÇÅËæº„ÅøÁîüÊàê]
    C --> C3[Ê≠£Ë¶èÂåñ]
    
    D --> D1[„Éá„Éº„ÇøÊ®ôÊ∫ñÂåñ]
    D --> D2[UMAPÈÅ©Áî®]
    D --> D3[Ê¨°ÂÖÉÂâäÊ∏õ]
    
    E --> E1[Áõ∏‰∫íÂà∞ÈÅîË∑ùÈõ¢Ë®àÁÆó]
    E --> E2[ÈöéÂ±§ÁöÑ„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞]
    E --> E3[„ÇØ„É©„Çπ„ÇøÈÅ∏Êäû]
    
    F --> F1[2DÊï£Â∏ÉÂõ≥]
    F --> F2[3DÊï£Â∏ÉÂõ≥]
    F --> F3[„ÇØ„É©„Çπ„ÇøÂàÜÂ∏É]
    F --> F4[„ÉØ„Éº„Éâ„ÇØ„É©„Ç¶„Éâ]
    
    G --> G1[ÂìÅË≥™ÊåáÊ®ôË®àÁÆó]
    G --> G2[È°û‰ººÂ∫¶ÂàÜÊûê]
    G --> G3[„Éà„Éî„ÉÉ„ÇØ„É¢„Éá„É™„É≥„Ç∞]
```

### üìä „Éá„Éº„Çø„Éï„É≠„ÉºË©≥Á¥∞

#### 1. „ÉÜ„Ç≠„Çπ„ÉàÂÖ•Âäõ„Éï„Çß„Éº„Ç∫
```python
# Ë§áÊï∞„ÅÆÂÖ•ÂäõÊñπÊ≥ï„Çí„Çµ„Éù„Éº„Éà
def load_texts(self):
    if input_method == "sample":
        return self._load_sample_texts()
    elif input_method == "csv":
        return self._load_csv_texts()
    elif input_method == "manual":
        return self._load_manual_texts()
    elif input_method == "url":
        return self._load_url_texts()
```

#### 2. ÂâçÂá¶ÁêÜ„Éï„Çß„Éº„Ç∫
```python
def preprocess_texts(self, texts: List[str]) -> List[str]:
    processed_texts = []
    for text in texts:
        # „ÇØ„É™„Éº„Éã„É≥„Ç∞
        cleaned = self.clean_text(text)
        # „Çπ„Éà„ÉÉ„Éó„ÉØ„Éº„ÉâÈô§ÂéªÔºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ
        if remove_stopwords:
            cleaned = self.remove_stopwords(cleaned)
        # „É¨„É≥„ÉûÂåñÔºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ
        if lemmatize:
            cleaned = self.lemmatize_text(cleaned)
        processed_texts.append(cleaned)
    return processed_texts
```

#### 3. BERTÂüã„ÇÅËæº„Åø„Éï„Çß„Éº„Ç∫
```python
def generate_embeddings(self, texts: List[str]) -> np.ndarray:
    # „É¢„Éá„É´Ë™≠„ÅøËæº„Åø
    self.load_model(model_name)
    
    # Âüã„ÇÅËæº„ÅøÁîüÊàê
    if isinstance(self.model, SentenceTransformer):
        embeddings = self.model.encode(texts, show_progress_bar=True)
    else:
        embeddings = self._generate_bert_embeddings(texts)
    
    return embeddings
```

#### 4. UMAPÊ¨°ÂÖÉÂâäÊ∏õ„Éï„Çß„Éº„Ç∫
```python
def apply_umap(self, embeddings: np.ndarray) -> np.ndarray:
    # „Éá„Éº„ÇøÊ®ôÊ∫ñÂåñ
    embeddings_scaled = self.scaler.fit_transform(embeddings)
    
    # UMAPÈÅ©Áî®
    self.umap_reducer = umap.UMAP(
        n_neighbors=n_neighbors,
        min_dist=min_dist,
        n_components=n_components,
        metric=metric,
        random_state=random_state
    )
    
    umap_embeddings = self.umap_reducer.fit_transform(embeddings_scaled)
    return umap_embeddings
```

#### 5. HDBSCAN„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞„Éï„Çß„Éº„Ç∫
```python
def apply_hdbscan(self, embeddings: np.ndarray) -> np.ndarray:
    # HDBSCAN„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞
    self.hdbscan_clusterer = hdbscan.HDBSCAN(
        min_cluster_size=min_cluster_size,
        min_samples=min_samples,
        cluster_selection_epsilon=cluster_selection_epsilon,
        alpha=alpha,
        prediction_data=True
    )
    
    cluster_labels = self.hdbscan_clusterer.fit_predict(embeddings)
    return cluster_labels
```

#### 6. ÂèØË¶ñÂåñ„Éï„Çß„Éº„Ç∫
```python
def create_visualizations(self):
    # 2DÊï£Â∏ÉÂõ≥
    fig_2d = self.create_umap_2d_plot(umap_embeddings, clusters, texts)
    
    # 3DÊï£Â∏ÉÂõ≥
    fig_3d = self.create_umap_3d_plot(umap_embeddings, clusters, texts)
    
    # „ÇØ„É©„Çπ„ÇøÂàÜÂ∏É
    fig_dist = self.create_cluster_distribution_plot(clusters)
    
    # „ÉØ„Éº„Éâ„ÇØ„É©„Ç¶„Éâ
    wordclouds = self.create_wordclouds_for_clusters(clusters, texts)
```

### ‚öôÔ∏è Ë®≠ÂÆö„Éï„É≠„Éº

```mermaid
graph LR
    A[„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Ëµ∑Âãï] --> B[Ë®≠ÂÆöË™≠„ÅøËæº„Åø]
    B --> C[„É¢„Éá„É´ÂàùÊúüÂåñ]
    C --> D[UIÊßãÁØâ]
    D --> E[„É¶„Éº„Ç∂„ÉºÂÖ•ÂäõÂæÖÊ©ü]
    E --> F[„Éë„É©„É°„Éº„ÇøË®≠ÂÆö]
    F --> G[Âá¶ÁêÜÂÆüË°å]
    G --> H[ÁµêÊûúË°®Á§∫]
    H --> I[ÂàÜÊûêÂÆüË°å]
    I --> J[„Ç®„ÇØ„Çπ„Éù„Éº„Éà]
```

## „Ç§„É≥„Çπ„Éà„Éº„É´

### Prerequisites
- Python 3.8 or higher
- uv package manager (recommended)

### Setup
```bash
# Clone the repository
git clone <repository-url>
cd bert_umap_hdbscan

# Install dependencies using uv
uv sync

# Activate virtual environment
source .venv/bin/activate

# Run the application
uv run streamlit run app.py
```

### Alternative Installation
```bash
# Using pip
pip install -e .

# Run the application
streamlit run app.py
```

## ‰ΩøÁî®ÊñπÊ≥ï

### 1. Text Input
Choose from multiple input methods:
- **Sample Texts**: Pre-loaded text categories (Technology, Science, Business)
- **Upload CSV**: Upload a CSV file with a 'text' column
- **Manual Input**: Enter texts directly in the text area
- **URL Input**: Fetch texts from a URL

### 2. Configuration
Adjust parameters in the sidebar:
- **BERT Model**: Select from available models
- **UMAP Parameters**: Configure dimensionality reduction
- **HDBSCAN Parameters**: Set clustering parameters

### 3. Processing
Click "Start Processing" to run the pipeline:
1. BERT embedding generation
2. UMAP dimensionality reduction
3. HDBSCAN clustering

### 4. Visualization
Explore results through various visualizations:
- **UMAP 2D/3D Scatter Plots**: Interactive cluster visualization
- **Cluster Distribution**: Bar chart of cluster sizes
- **Word Clouds**: Visual representation of cluster content

### 5. Analysis
Perform detailed analysis:
- **Cluster Analysis**: Detailed statistics for each cluster
- **Text Similarity**: Compare similarity between texts
- **Topic Modeling**: Extract topics using LDA
- **Export Results**: Download results as CSV

## „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£

### Core Modules

#### `app.py`
Main Streamlit application with UI components and workflow management.

#### `text_processor.py`
Text preprocessing utilities:
- Text cleaning and normalization
- Stopword removal and lemmatization
- Text validation and statistics

#### `bert_embedder.py`
BERT embedding generation:
- Model loading and management
- Embedding generation for texts
- Similarity computation

#### `clustering_manager.py`
UMAP and HDBSCAN clustering:
- Dimensionality reduction with UMAP
- Density-based clustering with HDBSCAN
- Clustering statistics and metrics

#### `visualization_manager.py`
Interactive visualizations:
- 2D/3D scatter plots
- Cluster distribution charts
- Word clouds and heatmaps

## Ë®≠ÂÆö

### BERT Models
- `sentence-transformers/all-MiniLM-L6-v2` (default)
- `sentence-transformers/all-mpnet-base-v2`
- `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`
- `bert-base-uncased`

### UMAP Parameters
- **n_neighbors**: Number of neighbors (5-100)
- **min_dist**: Minimum distance between points (0.0-1.0)
- **n_components**: Output dimensions (2-10)

### HDBSCAN Parameters
- **min_cluster_size**: Minimum cluster size (2-50)
- **min_samples**: Minimum samples in neighborhood (1-20)

## „Éë„Éï„Ç©„Éº„Éû„É≥„Çπ

### Model Performance
| Model | Embedding Dimension | Speed | Quality |
|-------|-------------------|-------|---------|
| all-MiniLM-L6-v2 | 384 | Fast | High |
| all-mpnet-base-v2 | 768 | Medium | Very High |
| paraphrase-multilingual-MiniLM-L12-v2 | 384 | Fast | High |
| bert-base-uncased | 768 | Slow | Very High |

### Clustering Quality Metrics
- **Silhouette Score**: Measures cluster cohesion and separation
- **Calinski-Harabasz Score**: Ratio of between-cluster to within-cluster variance
- **Davies-Bouldin Score**: Average similarity measure of clusters

## ‰æã

### Sample Text Categories

#### Technology
```
- Artificial intelligence is transforming industries worldwide.
- Machine learning algorithms are becoming more sophisticated.
- Deep learning has revolutionized computer vision.
- Natural language processing enables better communication.
- Data science is essential for modern business decisions.
```

#### Science
```
- Quantum physics challenges our understanding of reality.
- Climate change affects global ecosystems.
- Genetic engineering advances medical treatments.
- Astronomy reveals the universe's mysteries.
- Chemistry explains molecular interactions.
```

#### Business
```
- Marketing strategies drive customer engagement.
- Financial planning ensures long-term success.
- Human resources manage employee relations.
- Operations management optimizes processes.
- Strategic planning guides organizational growth.
```

## API „É™„Éï„Ç°„É¨„É≥„Çπ

### TextProcessor
```python
processor = TextProcessor()
cleaned_texts = processor.preprocess_texts(texts, remove_stopwords=True)
stats = processor.get_text_statistics(texts)
```

### BERTEmbedder
```python
embedder = BERTEmbedder()
embeddings = embedder.generate_embeddings(texts, model_name="sentence-transformers/all-MiniLM-L6-v2")
similarity = embedder.compute_similarity(embeddings, method="cosine")
```

### ClusteringManager
```python
manager = ClusteringManager()
umap_embeddings = manager.apply_umap(embeddings, n_components=2)
clusters = manager.apply_hdbscan(umap_embeddings, min_cluster_size=5)
stats = manager.get_clustering_statistics(clusters)
```

### VisualizationManager
```python
viz = VisualizationManager()
fig = viz.create_umap_2d_plot(umap_embeddings, clusters, texts)
wordcloud = viz.create_wordcloud(cluster_texts)
```

## „Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞

### Common Issues

#### Model Loading Errors
- Ensure internet connection for model download
- Check available disk space
- Verify CUDA installation for GPU acceleration

#### Memory Issues
- Reduce batch size for large text collections
- Use smaller BERT models
- Process texts in smaller chunks

#### Clustering Quality
- Adjust HDBSCAN parameters
- Try different UMAP configurations
- Preprocess texts more thoroughly

### Performance Tips
- Use GPU acceleration when available
- Process large datasets in batches
- Cache embeddings for repeated analysis
- Use appropriate model size for your use case

## Ë≤¢ÁåÆ

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## „É©„Ç§„Çª„É≥„Çπ

This project is licensed under the MIT License - see the LICENSE file for details.

## Citation

If you use this application in your research, please cite:

```bibtex
@software{bert_umap_hdbscan_clustering,
  title={BERT + UMAP + HDBSCAN Text Clustering Application},
  author={mutomasa},
  year={2025},
  url={https://github.com/mutomasa/bert_umap_hdbscan}
}
```

## Acknowledgments

- [Sentence Transformers](https://www.sbert.net/) for BERT embeddings
- [UMAP](https://umap-learn.readthedocs.io/) for dimensionality reduction
- [HDBSCAN](https://hdbscan.readthedocs.io/) for clustering
- [Streamlit](https://streamlit.io/) for the web interface
- [Plotly](https://plotly.com/) for interactive visualizations 